# -*- coding: utf-8 -*-
"""Hamza_Task_VGG16.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bojrgBxIeHQnheCXzuIPYcTBhzNd5MIv
"""

import os
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split

import cv2
tumors_images=os.listdir('/content/drive/My Drive/new data/tumor')

from tqdm import tqdm
tumors_files=[]
for t_image in tqdm(tumors_images):
  #print(os.path.join('/content/drive/My Drive/HamzaTask/new data/tumor',t_image))
  img = cv2.imread(os.path.join('/content/drive/My Drive/new data/tumor',t_image))
  img = cv2.resize(img,(224,224))
  img=img-np.mean(img)/np.std(img)
  tumors_files.append(img)

tumors_files=np.asarray(tumors_files)

tumors_files.shape

np.save('/content/drive/My Drive/HamzaTask/BRATS2018/tumors_files.npy',tumors_files)

from tqdm import tqdm
non_tumors_images=os.listdir('/content/drive/My Drive/new data/non-tumor')
non_tumors_files=[]
for t_image in tqdm(non_tumors_images):
  img = cv2.imread(os.path.join('/content/drive/My Drive/new data/non-tumor',t_image))
  img = cv2.resize(img,(224,224))
  img=img-np.mean(img)/np.std(img)
  non_tumors_files.append(img)

non_tumors_files=np.asarray(non_tumors_files)

non_tumors_files.shape

np.save('/content/drive/My Drive/HamzaTask/BRATS2018/non_tumors_files.npy',tumors_files)

arr1=np.zeros(941)

arr2=np.ones(851)

arr1.shape

arr1=np.reshape(arr1,(941,1))

arr2=np.reshape(arr2,(851,1))

arr1.shape

arr2.shape

a=arr1
b=arr2

c=[]
for i in range(len(arr1)):
  c.append(a[i])
for i in range(len(arr2)):
  c.append(b[i])

c=np.asarray(c)

c.shape

images=[]
for i in range(len(tumors_files)):
  images.append(tumors_files[i])
for i in range(len(non_tumors_files)):
  images.append(non_tumors_files[i])

images=np.asarray(images)

images.shape

from keras.utils import to_categorical
y = to_categorical(c)

y

np.save('/content/drive/My Drive/HamzaTask/BRATS2018/images.npy',images)
np.save('/content/drive/My Drive/HamzaTask/BRATS2018/labels.npy',y)

import numpy as np
images=np.load('/content/drive/My Drive/HamzaTask/BRATS2018/images.npy')
labels=np.load('/content/drive/My Drive/HamzaTask/BRATS2018/labels.npy')

images.shape

labels.shape

import pandas as pd
import numpy as np
import os
import tensorflow as tf
import keras
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.vgg16 import preprocess_input
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
image_size = [224,224]

vgg = VGG16(input_shape= image_size+[3],weights='imagenet',include_top=False)

x = vgg.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024,activation='relu')(x)
x = Dense(1024,activation='relu')(x)
x = Dense(512, activation='relu')(x)
preds = Dense(2,activation='softmax')(x)
model = Model(inputs = vgg.input,outputs=preds)

model.summary()

X_train, X_val, Y_train, Y_val = train_test_split(images, labels, test_size = 0.1, random_state=2)
print("x_train shape",X_train.shape)
print("x_val shape",X_val.shape)
print("y_train shape",Y_train.shape)
print("y_val shape",Y_val.shape)

model.compile(optimizer='Adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
history=model.fit(x=X_train,y=Y_train,batch_size=128,epochs=25,validation_data=(X_val, Y_val))

from sklearn.metrics import confusion_matrix
import itertools

from matplotlib import pyplot as plt
plt.figure(figsize=(15,10))
plt.grid(color='r', linestyle='dotted', linewidth=0.5)
plt.plot(history.history['accuracy'], 'o-', color = '#9900CC')
plt.plot(history.history['val_accuracy'], 'o-', color = '#00cc33')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

from keras.engine.topology import Input

height_vgg16 = 224
width_vgg16 = int(height_vgg16*0.75)
target_size_vgg16 = (width_vgg16,height_vgg16)
layer_name_vgg16 = 'block5_pool'
height_vgg16=224
width_vgg16=224
model_input_vgg16 = Input((height_vgg16, width_vgg16, 3))
#base_model = VGG19(include_top = False,weights='imagenet',input_tensor = model_input, input_shape=target_size)
base_model_vgg16 = VGG16(weights='imagenet', include_top=False,input_tensor = model_input_vgg16, input_shape=(height_vgg16, width_vgg16, 3))
model_vgg16 = Model(inputs=model_input_vgg16, outputs=base_model_vgg16.get_layer(layer_name_vgg16).output)
model_vgg16.summary()

vgg_features=model_vgg16.predict(images)

vgg_features.shape

vgg_features_new=vgg_features.reshape(vgg_features.shape[0],7*7*512)

vgg_features_new

X_train, X_val, Y_train, Y_val = train_test_split(vgg_features_new, c, test_size = 0.1, random_state=2)

from sklearn.svm import SVC

svm_model = SVC(kernel='linear')
svm_model.fit(X_train, Y_train)
print('test set accuracy = ',svm_model.score(X_val, Y_val))
print('training set accuracy = ',svm_model.score(X_train, Y_train))

kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']#A function which returns the corresponding SVC model
def getClassifier(ktype):
    if ktype == 0:
        # Polynomial kernal
        return SVC(kernel='poly', degree=8, gamma="auto")
    elif ktype == 1:
        # Radial Basis Function kernal
        return SVC(kernel='rbf', gamma="auto")
    elif ktype == 2:
        # Sigmoid kernal
        return SVC(kernel='sigmoid', gamma="auto")
    elif ktype == 3:
        # Linear kernal
        return SVC(kernel='linear', gamma="auto")
for i in range(4):
    # Separate data into test and training sets
    X_train, X_test, y_train, y_test = train_test_split(vgg_features_new, c, test_size = 0.20)# Train a SVC model using different kernal
    svclassifier = getClassifier(i) 
    svclassifier.fit(X_train, y_train)# Make prediction
    y_pred = svclassifier.predict(X_test)# Evaluate our model
    print("Evaluation:", kernals[i], "kernel")
    print(classification_report(y_test,y_pred))

from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn.model_selection import GridSearchCV
parameters={'min_samples_split' : range(10,500,20),'max_depth': range(1,20,2)}
clf_tree=DecisionTreeClassifier()
clf=GridSearchCV(clf_tree,parameters)
clf.fit(X_train, Y_train)

pred=clf.predict(X_val)

from sklearn.metrics import accuracy_score
print(accuracy_score(pred,Y_val))

from sklearn import svm
from sklearn.metrics import classification_report
kernels = ['Polynomial', 'RBF', 'Sigmoid','Linear']#A function which returns the corresponding SVC model
def getClassifier(ktype):
    if ktype == 0:
        # Polynomial kernal
        return SVC(kernel='poly', degree=8, gamma="auto")
    elif ktype == 1:
        # Radial Basis Function kernal
        return SVC(kernel='rbf', gamma="auto")
    elif ktype == 2:
        # Sigmoid kernal
        return SVC(kernel='sigmoid', gamma="auto")
    elif ktype == 3:
        # Linear kernal
        return SVC(kernel='linear', gamma="auto")
for i in range(4):
    # Separate data into test and training sets
    x_train, x_test, y_train, y_test = train_test_split(vgg_features_new, c, test_size = 0.2)# Train a SVC model using different kernal
    svclassifier = getClassifier(i) 
    svclassifier.fit(x_train, y_train)# Make prediction
    y_pred = svclassifier.predict(x_test)# Evaluate our model
    print("Evaluation:", kernels[i], "kernel")
    print(classification_report(y_test,y_pred))

